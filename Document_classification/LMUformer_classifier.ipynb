{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BEST Statistics:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report:**\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.56      0.60      0.58      6000\n",
    "           1       0.75      0.64      0.69      6000\n",
    "           2       0.75      0.77      0.76      6000\n",
    "           3       0.49      0.57      0.52      6000\n",
    "           4       0.87      0.81      0.84      6000\n",
    "           5       0.90      0.84      0.87      6000\n",
    "           6       0.55      0.49      0.52      6000\n",
    "           7       0.68      0.70      0.69      6000\n",
    "           8       0.67      0.79      0.72      6000\n",
    "           9       0.78      0.70      0.74      6000\n",
    "    \n",
    "**total dataset size** = 60000\n",
    "\n",
    "**accuracy** = 0.69    \n",
    " \n",
    "**macro avg**  \n",
    "**precision** = 0.70      \n",
    "**recall** = 0.69      \n",
    "**f1-score** = 0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aditya-venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-01 09:58:05.649494: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-01 09:58:05.661475: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733047085.675481 1358246 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733047085.679699 1358246 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 09:58:05.694162: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import fft\n",
    "import torch\n",
    "import numpy as np\n",
    "# from spikingjelly.clock_driven.neuron import MultiStepLIFNode\n",
    "# from spikingjelly.clock_driven import functional\n",
    "from scipy.signal import cont2discrete\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def get_model_size(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    param_size = 4  # Assuming float32 (4 bytes per parameter)\n",
    "    total_size = total_params * param_size\n",
    "    return total_size / (1024 ** 2)  # Convert bytes to MB\n",
    "\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "class LMUFFTCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, memory_size, seq_len, theta):\n",
    "        super(LMUFFTCell, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.memory_size = memory_size\n",
    "        self.seq_len = seq_len\n",
    "        self.theta = theta\n",
    "\n",
    "        self.W_u = nn.Linear(in_features = input_size, out_features = 1)\n",
    "        self.f_u = nn.ReLU()\n",
    "        self.W_h = nn.Linear(in_features = memory_size + input_size, out_features = hidden_size)\n",
    "        self.f_h = nn.ReLU()\n",
    "\n",
    "        A, B = self.stateSpaceMatrices()\n",
    "        self.register_buffer(\"A\", A) # [memory_size, memory_size]\n",
    "        self.register_buffer(\"B\", B) # [memory_size, 1]\n",
    "\n",
    "        H, fft_H = self.impulse()\n",
    "        self.register_buffer(\"H\", H) # [memory_size, seq_len]\n",
    "        self.register_buffer(\"fft_H\", fft_H) # [memory_size, seq_len + 1]\n",
    "\n",
    "    def stateSpaceMatrices(self):\n",
    "        \"\"\" Returns the discretized state space matrices A and B \"\"\"\n",
    "\n",
    "        Q = np.arange(self.memory_size, dtype = np.float64).reshape(-1, 1)\n",
    "        R = (2*Q + 1) / self.theta\n",
    "        i, j = np.meshgrid(Q, Q, indexing = \"ij\")\n",
    "\n",
    "        # Continuous\n",
    "        A = R * np.where(i < j, -1, (-1.0)**(i - j + 1))\n",
    "        B = R * ((-1.0)**Q)\n",
    "        C = np.ones((1, self.memory_size))\n",
    "        D = np.zeros((1,))\n",
    "\n",
    "        # Convert to discrete\n",
    "        A, B, C, D, dt = cont2discrete(\n",
    "            system = (A, B, C, D), \n",
    "            dt = 1.0, \n",
    "            method = \"zoh\"\n",
    "        )\n",
    "\n",
    "        # To torch.tensor\n",
    "        A = torch.from_numpy(A).float() # [memory_size, memory_size]\n",
    "        B = torch.from_numpy(B).float() # [memory_size, 1]\n",
    "        \n",
    "        return A, B\n",
    "\n",
    "    def impulse(self):\n",
    "        \"\"\" Returns the matrices H and the 1D Fourier transform of H (Equations 23, 26 of the paper) \"\"\"\n",
    "\n",
    "        H = []\n",
    "        A_i = torch.eye(self.memory_size).to(self.A.device) \n",
    "        for t in range(self.seq_len):\n",
    "            H.append(A_i @ self.B)\n",
    "            A_i = self.A @ A_i\n",
    "\n",
    "        H = torch.cat(H, dim = -1) # [memory_size, seq_len]\n",
    "        fft_H = fft.rfft(H, n = 2*self.seq_len, dim = -1) # [memory_size, seq_len + 1]\n",
    "\n",
    "        return H, fft_H\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            x (torch.tensor): \n",
    "                Input of size [batch_size, seq_len, input_size]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, input_size = x.shape\n",
    "        # print(\"batch_size, seq_len, input_size\", batch_size, seq_len, input_size)\n",
    "\n",
    "        # Equation 18 of the paper\n",
    "        u = self.f_u(self.W_u(x)) # [batch_size, seq_len, 1]\n",
    "\n",
    "        # Equation 26 of the paper\n",
    "        fft_input = u.permute(0, 2, 1) # [batch_size, 1, seq_len]\n",
    "        fft_u = fft.rfft(fft_input, n = 2*seq_len, dim = -1) # [batch_size, seq_len, seq_len+1]\n",
    "\n",
    "        # Element-wise multiplication (uses broadcasting)\n",
    "        # [batch_size, 1, seq_len+1] * [1, memory_size, seq_len+1]\n",
    "        temp = fft_u * self.fft_H.unsqueeze(0) # [batch_size, memory_size, seq_len+1]\n",
    "\n",
    "        m = fft.irfft(temp, n = 2*seq_len, dim = -1) # [batch_size, memory_size, seq_len+1]\n",
    "        m = m[:, :, :seq_len] # [batch_size, memory_size, seq_len]\n",
    "        m = m.permute(0, 2, 1) # [batch_size, seq_len, memory_size]\n",
    "\n",
    "        # Equation 20 of the paper (W_m@m + W_x@x  W@[m;x])\n",
    "        input_h = torch.cat((m, x), dim = -1) # [batch_size, seq_len, memory_size + input_size]\n",
    "        h = self.f_h(self.W_h(input_h)) # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        h_n = h[:, -1, :] # [batch_size*T, hidden_size]\n",
    "\n",
    "        return h, h_n\n",
    "    \n",
    "    def forward_recurrent(self, x, m_last):\n",
    "        u = self.f_u(self.W_u(x)) # [batch_size, seq_len, 1]\n",
    "        # A: torch.Size([512, 512]), m_last: torch.Size([256, 512]), B: torch.Size([512, 1]), u: torch.Size([256, 1])\n",
    "        m = m_last @ self.A.T + u @ self.B.T  # [batch_size, memory_size]\n",
    "        input_h = torch.cat((m, x), dim = -1) # [batch_size, seq_len, memory_size + input_size]\n",
    "        h = self.f_h(self.W_h(input_h)) # [batch_size, seq_len, hidden_size]\n",
    "\n",
    "        return h, m\n",
    "\n",
    "class LMU(nn.Module):\n",
    "    def __init__(self, dim, T, use_all_h=True):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_size = dim\n",
    "        self.memory_size = dim\n",
    "        self.use_all_h = use_all_h\n",
    "        self.lmu = LMUFFTCell(input_size=dim, hidden_size=self.hidden_size, memory_size=self.memory_size, seq_len=T, theta=T)\n",
    "        # self.lmu = LMUFFTCell(input_size=dim, hidden_size=self.hidden_size, memory_size=self.memory_size, seq_len=64, theta=64)\n",
    "\n",
    "        self.proj_conv = nn.Conv1d(dim, dim, kernel_size=1, stride=1)\n",
    "        self.proj_bn = nn.BatchNorm1d(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(-1,-2).contiguous() # B, C, N -> B, N, C\n",
    "        h, _ = self.lmu(x) # B, N, C; B, C\n",
    "        \n",
    "        x = h.transpose(-1,-2).contiguous() #if self.use_all_h else h_n.unsqueeze(-1) # h or h_n\n",
    "\n",
    "        x = self.proj_conv(x)\n",
    "        x = self.proj_bn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class LinearFFN(nn.Module):\n",
    "    def __init__(self, in_features, pre_norm=False, hidden_features=None, out_features=None, drop=0., act_type='spike'):\n",
    "        super().__init__()\n",
    "        self.pre_norm = pre_norm\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "\n",
    "        self.fc1_linear  = nn.Linear(in_features, hidden_features)\n",
    "        self.fc1_ln = nn.LayerNorm(hidden_features)\n",
    "        self.fc1_lif = get_act(act_type if act_type == 'spike' else 'gelu', tau=2.0, detach_reset=True)\n",
    "\n",
    "        self.fc2_linear = nn.Linear(hidden_features, out_features)\n",
    "        self.fc2_ln = nn.LayerNorm(out_features)\n",
    "        self.fc2_lif = get_act(act_type, tau=2.0, detach_reset=True)\n",
    " \n",
    "        self.c_hidden = hidden_features\n",
    "        self.c_output = out_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,C,N = x.shape\n",
    "        # \n",
    "        x = x.permute(0,2,1) # B, N, C\n",
    "        # x = x.reshape(B*N, C)\n",
    "        if self.pre_norm:\n",
    "            x = self.fc1_ln(x)\n",
    "            x = self.fc1_lif(x)\n",
    "            x = self.fc1_linear(x)\n",
    "            \n",
    "            x = self.fc2_ln(x)\n",
    "            x = self.fc2_lif(x)\n",
    "            x = self.fc2_linear(x)\n",
    "\n",
    "        else:\n",
    "            x = self.fc1_linear(x)\n",
    "            x = self.fc1_ln(x)\n",
    "            x = self.fc1_lif(x)\n",
    "\n",
    "            x = self.fc2_linear(x)\n",
    "            x = self.fc2_ln(x)\n",
    "            x = self.fc2_lif(x)\n",
    "\n",
    "        # x = x.reshape(B, N, self.c_output)\n",
    "        x = x.permute(0,2,1) # B, C, N\n",
    "        return x\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, T, mlp_ratio=4., act_type='spike'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = LMU(dim=dim, T=T)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = LinearFFN(in_features=dim, hidden_features=mlp_hidden_dim, act_type=act_type)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(x)\n",
    "        x = x + self.mlp(x)\n",
    "        return x\n",
    "\n",
    "class perm(nn.Module):\n",
    "    def __init__(self, a, b, c) -> None:\n",
    "        super().__init__()\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.permute(self.a,self.b,self.c).contiguous()\n",
    "\n",
    "def get_act(act_type = 'spike', **act_params):\n",
    "    '''\n",
    "    act_type :- spike, gelu, relu, identity\n",
    "\n",
    "    output :- class <act_type>\n",
    "    '''\n",
    "    act_type = act_type.lower()\n",
    "    # if act_type == 'spike':\n",
    "    #     return MultiStepLIFNode(**act_params, backend='cupy')\n",
    "    #     # act_params['init_tau'] = act_params.pop('tau')\n",
    "    #     # return MultiStepParametricLIFNode(**act_params, backend=\"cupy\")\n",
    "    if act_type == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif act_type == 'gelu':\n",
    "        return nn.GELU()\n",
    "    elif act_type == 'identity':\n",
    "        return nn.Identity()\n",
    "    \n",
    "def get_conv_block(T, dim, act_type, kernel_size=3, padding=1, groups=1):\n",
    "    return [\n",
    "        perm(0,2,1),\n",
    "        nn.Conv1d(dim, dim, kernel_size=kernel_size, stride=1, padding=padding, groups=groups, bias=False),\n",
    "        nn.BatchNorm1d(dim),\n",
    "        perm(1,2,0),\n",
    "        get_act(act_type, tau=2.0, detach_reset=True),\n",
    "        perm(2,1,0)\n",
    "]\n",
    "\n",
    "class Conv1d4EB(nn.Module):\n",
    "    def __init__(self, T=128, vw_dim=256, act_type='spike'):\n",
    "        super().__init__()\n",
    "\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        groups = 1\n",
    "        self.proj_conv = nn.ModuleList(\n",
    "            [perm(0,2,1)]+\\\n",
    "            get_conv_block(T, vw_dim, act_type)+\\\n",
    "            get_conv_block(T, vw_dim, act_type, kernel_size=kernel_size, padding=padding, groups=groups)+\\\n",
    "            get_conv_block(T, vw_dim, act_type, kernel_size=kernel_size, padding=padding, groups=groups)+\\\n",
    "            get_conv_block(T, vw_dim, act_type, kernel_size=kernel_size, padding=padding, groups=groups)+\\\n",
    "            [perm(0,2,1)]\n",
    "        )\n",
    "        self.rpe_conv = nn.ModuleList(\n",
    "            [perm(0,2,1)]+\\\n",
    "            get_conv_block(T, vw_dim, act_type, kernel_size=kernel_size, padding=padding, groups=groups)+\\\n",
    "            [perm(0,2,1)]\n",
    "        )\n",
    "        self.act_loss = 0.0\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        for ele in self.proj_conv:\n",
    "            x = ele(x)\n",
    "\n",
    "        x_rpe = x.clone()\n",
    "        for ele in self.rpe_conv:\n",
    "            x_rpe = ele(x_rpe)\n",
    "\n",
    "        x = x + x_rpe\n",
    "        \n",
    "        return x \n",
    "\n",
    "from transformers import BertModel , BertTokenizer\n",
    "\n",
    "class LMUformer_sq_Classifier(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, hidden_size, num_classes, act_type='relu', T=784, test_mode='all_seq',with_head_lif=False):\n",
    "        super().__init__()\n",
    "        self.with_head_lif = with_head_lif\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "        bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.embedding = nn.Embedding.from_pretrained(bert_model.embeddings.word_embeddings.weight,freeze=False)\n",
    "\n",
    "        self.in_layer = nn.Linear(768, hidden_size)\n",
    "\n",
    "        self.patch_embed = Conv1d4EB(T=T, vw_dim=hidden_size, act_type=act_type)\n",
    "\n",
    "        self.block = nn.ModuleList([\n",
    "            Block(dim=hidden_size, T=T, act_type=act_type)\n",
    "            for j in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # classification head\n",
    "        if self.with_head_lif:\n",
    "            self.head_bn = nn.BatchNorm1d(hidden_size)\n",
    "            self.head_lif = get_act(act_type, tau=2.0, detach_reset=True)\n",
    "\n",
    "        self.head = nn.Linear(hidden_size, num_classes)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        for blk in self.block:\n",
    "            x = blk(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, labels=None, infer=False):\n",
    "        self.act_loss = 0.0\n",
    "        x = self.embedding(x)\n",
    "        x = self.in_layer(x)\n",
    "        x = x.permute(0, 2, 1).contiguous()\n",
    "        x = self.forward_features(x)    # b, d, t -> b, d, t\n",
    "\n",
    "        if self.with_head_lif:\n",
    "            x = self.head_bn(x)         # b, d, t \n",
    "            x = self.head_lif(x)        # b, d, t\n",
    "\n",
    "        x = x.permute(0, 2, 1).contiguous()\n",
    "        x = torch.mean(x, 1)\n",
    "        out = self.head(x)\n",
    "        if infer:\n",
    "            return out\n",
    "        \n",
    "        return self.loss(out, labels)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Training with 100000 examples\n",
      "Loading tokenizer...\n",
      "Total parameters: 63087116\n",
      "Trainable parameters: 63087116\n",
      "Model size: 240.66 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class YahooDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=256):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Combine text fields and clean up\n",
    "        self.texts = (dataframe['question_title'].fillna('') + ' [SEP] ' + \n",
    "                     dataframe['question_content'].fillna('') + ' [SEP] ' + \n",
    "                     dataframe['best_answer'].fillna(''))\n",
    "        \n",
    "        # Convert to zero-based indexing\n",
    "        self.labels = dataframe['class'] - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc='Training')\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # print(input_ids.shape)\n",
    "        # print(labels.shape)\n",
    "        # print(attention_mask.shape)\n",
    "        loss = model(\n",
    "            input_ids,\n",
    "            labels=labels\n",
    "        )\n",
    "        # print(loss)\n",
    "        # assert False,''\n",
    "                \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids,\n",
    "                infer=True\n",
    "            )\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    \n",
    "    return classification_report(true_labels, predictions, zero_division=0)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load datasets\n",
    "print('Loading datasets...')\n",
    "train_df = pd.read_csv('train.csv', \n",
    "                        names=['class', 'question_title', 'question_content', 'best_answer'])\n",
    "\n",
    "# Sample 10,000 examples per class for balanced training\n",
    "samples_per_class = 10000\n",
    "sampled_train_df = []\n",
    "\n",
    "for class_idx in range(1, 11):  # 10 classes\n",
    "    class_data = train_df[train_df['class'] == class_idx]\n",
    "    sampled_class = class_data.sample(n=min(samples_per_class, len(class_data)), \n",
    "                                    random_state=42)\n",
    "    sampled_train_df.append(sampled_class)\n",
    "\n",
    "train_df = pd.concat(sampled_train_df, ignore_index=True)\n",
    "print(f'Training with {len(train_df)} examples')\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv('test.csv', \n",
    "                        names=['class', 'question_title', 'question_content', 'best_answer'])\n",
    "\n",
    "# Load classes\n",
    "with open('classes.txt', 'r') as f:\n",
    "    class_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Initialize tokenizer\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = LMUformer_sq_Classifier(num_classes=10, input_size=512, num_layers=2, hidden_size=1024, T=256).to(device)\n",
    "\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "\n",
    "size_in_mb = get_model_size(model)\n",
    "print(f\"Model size: {size_in_mb:.2f} MB\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = YahooDataset(train_df, tokenizer)\n",
    "test_dataset = YahooDataset(test_df, tokenizer)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32  # Can use larger batch size with smaller model\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=RandomSampler(train_dataset)\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [13:51<00:00,  3.76it/s, loss=0.9979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.1376\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [03:56<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.57      6000\n",
      "           1       0.66      0.77      0.71      6000\n",
      "           2       0.75      0.76      0.76      6000\n",
      "           3       0.56      0.47      0.51      6000\n",
      "           4       0.84      0.84      0.84      6000\n",
      "           5       0.88      0.84      0.86      6000\n",
      "           6       0.56      0.52      0.54      6000\n",
      "           7       0.58      0.78      0.66      6000\n",
      "           8       0.75      0.71      0.73      6000\n",
      "           9       0.77      0.74      0.76      6000\n",
      "\n",
      "    accuracy                           0.70     60000\n",
      "   macro avg       0.70      0.70      0.69     60000\n",
      "weighted avg       0.70      0.70      0.69     60000\n",
      "\n",
      "Saved best model with accuracy: 0.6900\n",
      "\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [13:52<00:00,  3.76it/s, loss=0.4604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.8642\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [03:52<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.54      0.57      6000\n",
      "           1       0.75      0.68      0.72      6000\n",
      "           2       0.72      0.82      0.77      6000\n",
      "           3       0.55      0.51      0.53      6000\n",
      "           4       0.85      0.85      0.85      6000\n",
      "           5       0.86      0.87      0.87      6000\n",
      "           6       0.66      0.46      0.54      6000\n",
      "           7       0.65      0.74      0.69      6000\n",
      "           8       0.65      0.82      0.73      6000\n",
      "           9       0.77      0.77      0.77      6000\n",
      "\n",
      "    accuracy                           0.71     60000\n",
      "   macro avg       0.71      0.71      0.70     60000\n",
      "weighted avg       0.71      0.71      0.70     60000\n",
      "\n",
      "Saved best model with accuracy: 0.7000\n",
      "\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [12:02<00:00,  4.32it/s, loss=1.1622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.7029\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [02:20<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.63      0.57      6000\n",
      "           1       0.68      0.74      0.71      6000\n",
      "           2       0.69      0.82      0.75      6000\n",
      "           3       0.62      0.41      0.49      6000\n",
      "           4       0.87      0.83      0.85      6000\n",
      "           5       0.82      0.88      0.85      6000\n",
      "           6       0.65      0.45      0.53      6000\n",
      "           7       0.67      0.71      0.69      6000\n",
      "           8       0.72      0.75      0.73      6000\n",
      "           9       0.72      0.75      0.74      6000\n",
      "\n",
      "    accuracy                           0.70     60000\n",
      "   macro avg       0.70      0.70      0.69     60000\n",
      "weighted avg       0.70      0.70      0.69     60000\n",
      "\n",
      "\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [08:10<00:00,  6.37it/s, loss=0.5467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.5359\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [02:22<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.49      0.54      6000\n",
      "           1       0.66      0.75      0.70      6000\n",
      "           2       0.73      0.77      0.75      6000\n",
      "           3       0.57      0.45      0.50      6000\n",
      "           4       0.80      0.87      0.84      6000\n",
      "           5       0.91      0.81      0.86      6000\n",
      "           6       0.60      0.42      0.50      6000\n",
      "           7       0.69      0.67      0.68      6000\n",
      "           8       0.58      0.83      0.69      6000\n",
      "           9       0.69      0.79      0.74      6000\n",
      "\n",
      "    accuracy                           0.69     60000\n",
      "   macro avg       0.68      0.69      0.68     60000\n",
      "weighted avg       0.68      0.69      0.68     60000\n",
      "\n",
      "\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [08:12<00:00,  6.34it/s, loss=0.4225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3692\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [02:21<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.54      6000\n",
      "           1       0.66      0.70      0.68      6000\n",
      "           2       0.72      0.77      0.74      6000\n",
      "           3       0.48      0.49      0.49      6000\n",
      "           4       0.82      0.85      0.83      6000\n",
      "           5       0.85      0.85      0.85      6000\n",
      "           6       0.52      0.47      0.49      6000\n",
      "           7       0.70      0.65      0.67      6000\n",
      "           8       0.70      0.71      0.71      6000\n",
      "           9       0.73      0.69      0.71      6000\n",
      "\n",
      "    accuracy                           0.67     60000\n",
      "   macro avg       0.67      0.67      0.67     60000\n",
      "weighted avg       0.67      0.67      0.67     60000\n",
      "\n",
      "\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [08:16<00:00,  6.29it/s, loss=0.1276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.2135\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [02:21<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.51      0.53      6000\n",
      "           1       0.71      0.63      0.67      6000\n",
      "           2       0.72      0.76      0.74      6000\n",
      "           3       0.47      0.47      0.47      6000\n",
      "           4       0.82      0.84      0.83      6000\n",
      "           5       0.87      0.83      0.85      6000\n",
      "           6       0.43      0.53      0.47      6000\n",
      "           7       0.69      0.65      0.67      6000\n",
      "           8       0.67      0.72      0.69      6000\n",
      "           9       0.75      0.68      0.71      6000\n",
      "\n",
      "    accuracy                           0.66     60000\n",
      "   macro avg       0.67      0.66      0.66     60000\n",
      "weighted avg       0.67      0.66      0.66     60000\n",
      "\n",
      "\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [08:08<00:00,  6.40it/s, loss=0.1595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1096\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [02:19<00:00, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.51      0.53      6000\n",
      "           1       0.66      0.68      0.67      6000\n",
      "           2       0.74      0.74      0.74      6000\n",
      "           3       0.49      0.46      0.47      6000\n",
      "           4       0.82      0.84      0.83      6000\n",
      "           5       0.86      0.84      0.85      6000\n",
      "           6       0.46      0.49      0.47      6000\n",
      "           7       0.66      0.67      0.67      6000\n",
      "           8       0.71      0.69      0.70      6000\n",
      "           9       0.70      0.73      0.71      6000\n",
      "\n",
      "    accuracy                           0.66     60000\n",
      "   macro avg       0.66      0.66      0.66     60000\n",
      "weighted avg       0.66      0.66      0.66     60000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training settings\n",
    "epochs = 7\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)  # Slightly higher learning rate\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "print('Starting training...')\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "    \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(f'Average training loss: {train_loss:.4f}')\n",
    "    \n",
    "    print('\\nEvaluating...')\n",
    "    report = evaluate(model, test_loader, device)\n",
    "    print('\\nClassification Report:')\n",
    "    print(report)\n",
    "    \n",
    "    # Save model if it improves\n",
    "    accuracy = float(report.split('\\n')[-2].split()[-2])\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), 'best_yahoo_LMUformer_2layer.pt')\n",
    "        print(f'Saved best model with accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:57<00:00, 17.56it/s, loss=1.2577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.2287\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:08<00:00, 27.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.56      6000\n",
      "           1       0.65      0.77      0.70      6000\n",
      "           2       0.78      0.73      0.75      6000\n",
      "           3       0.55      0.47      0.51      6000\n",
      "           4       0.80      0.84      0.82      6000\n",
      "           5       0.79      0.89      0.84      6000\n",
      "           6       0.53      0.49      0.51      6000\n",
      "           7       0.64      0.71      0.67      6000\n",
      "           8       0.69      0.75      0.72      6000\n",
      "           9       0.76      0.73      0.75      6000\n",
      "\n",
      "    accuracy                           0.69     60000\n",
      "   macro avg       0.68      0.69      0.68     60000\n",
      "weighted avg       0.68      0.69      0.68     60000\n",
      "\n",
      "Saved best model with accuracy: 0.6800\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:01<00:00, 17.18it/s, loss=1.1389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.9080\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:09<00:00, 26.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.60      0.58      6000\n",
      "           1       0.75      0.64      0.69      6000\n",
      "           2       0.75      0.77      0.76      6000\n",
      "           3       0.49      0.57      0.52      6000\n",
      "           4       0.87      0.81      0.84      6000\n",
      "           5       0.90      0.84      0.87      6000\n",
      "           6       0.55      0.49      0.52      6000\n",
      "           7       0.68      0.70      0.69      6000\n",
      "           8       0.67      0.79      0.72      6000\n",
      "           9       0.78      0.70      0.74      6000\n",
      "\n",
      "    accuracy                           0.69     60000\n",
      "   macro avg       0.70      0.69      0.69     60000\n",
      "weighted avg       0.70      0.69      0.69     60000\n",
      "\n",
      "Saved best model with accuracy: 0.6900\n",
      "\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:54<00:00, 17.88it/s, loss=0.9929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.7628\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:10<00:00, 26.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.52      0.56      6000\n",
      "           1       0.74      0.66      0.70      6000\n",
      "           2       0.72      0.79      0.75      6000\n",
      "           3       0.57      0.46      0.51      6000\n",
      "           4       0.79      0.88      0.83      6000\n",
      "           5       0.80      0.89      0.84      6000\n",
      "           6       0.57      0.47      0.51      6000\n",
      "           7       0.66      0.69      0.68      6000\n",
      "           8       0.67      0.78      0.72      6000\n",
      "           9       0.71      0.77      0.74      6000\n",
      "\n",
      "    accuracy                           0.69     60000\n",
      "   macro avg       0.68      0.69      0.68     60000\n",
      "weighted avg       0.68      0.69      0.68     60000\n",
      "\n",
      "\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:57<00:00, 17.59it/s, loss=0.7283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.6200\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:09<00:00, 26.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.53      0.53      6000\n",
      "           1       0.66      0.72      0.69      6000\n",
      "           2       0.75      0.72      0.73      6000\n",
      "           3       0.50      0.49      0.50      6000\n",
      "           4       0.82      0.85      0.83      6000\n",
      "           5       0.90      0.82      0.86      6000\n",
      "           6       0.51      0.48      0.50      6000\n",
      "           7       0.64      0.70      0.67      6000\n",
      "           8       0.71      0.72      0.72      6000\n",
      "           9       0.73      0.71      0.72      6000\n",
      "\n",
      "    accuracy                           0.67     60000\n",
      "   macro avg       0.68      0.67      0.67     60000\n",
      "weighted avg       0.68      0.67      0.67     60000\n",
      "\n",
      "\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:59<00:00, 17.38it/s, loss=0.3395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.4820\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:10<00:00, 26.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.53      6000\n",
      "           1       0.71      0.66      0.68      6000\n",
      "           2       0.67      0.79      0.72      6000\n",
      "           3       0.56      0.40      0.47      6000\n",
      "           4       0.81      0.83      0.82      6000\n",
      "           5       0.85      0.84      0.85      6000\n",
      "           6       0.52      0.45      0.48      6000\n",
      "           7       0.64      0.67      0.66      6000\n",
      "           8       0.66      0.75      0.70      6000\n",
      "           9       0.72      0.73      0.72      6000\n",
      "\n",
      "    accuracy                           0.67     60000\n",
      "   macro avg       0.66      0.67      0.66     60000\n",
      "weighted avg       0.66      0.67      0.66     60000\n",
      "\n",
      "\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:04<00:00, 16.94it/s, loss=0.1881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3551\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:10<00:00, 26.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.57      0.52      6000\n",
      "           1       0.70      0.62      0.66      6000\n",
      "           2       0.73      0.72      0.73      6000\n",
      "           3       0.47      0.46      0.46      6000\n",
      "           4       0.82      0.81      0.82      6000\n",
      "           5       0.89      0.80      0.84      6000\n",
      "           6       0.44      0.50      0.47      6000\n",
      "           7       0.65      0.65      0.65      6000\n",
      "           8       0.68      0.72      0.70      6000\n",
      "           9       0.74      0.68      0.71      6000\n",
      "\n",
      "    accuracy                           0.65     60000\n",
      "   macro avg       0.66      0.65      0.66     60000\n",
      "weighted avg       0.66      0.65      0.66     60000\n",
      "\n",
      "\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:06<00:00, 16.77it/s, loss=0.5009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.2541\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:09<00:00, 27.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.41      0.49      6000\n",
      "           1       0.66      0.60      0.63      6000\n",
      "           2       0.76      0.66      0.71      6000\n",
      "           3       0.41      0.53      0.46      6000\n",
      "           4       0.78      0.81      0.80      6000\n",
      "           5       0.84      0.83      0.84      6000\n",
      "           6       0.41      0.48      0.45      6000\n",
      "           7       0.61      0.67      0.63      6000\n",
      "           8       0.70      0.68      0.69      6000\n",
      "           9       0.71      0.69      0.70      6000\n",
      "\n",
      "    accuracy                           0.64     60000\n",
      "   macro avg       0.65      0.64      0.64     60000\n",
      "weighted avg       0.65      0.64      0.64     60000\n",
      "\n",
      "\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:59<00:00, 17.36it/s, loss=0.3773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1803\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:10<00:00, 26.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.49      0.51      6000\n",
      "           1       0.66      0.62      0.64      6000\n",
      "           2       0.74      0.68      0.71      6000\n",
      "           3       0.43      0.50      0.46      6000\n",
      "           4       0.78      0.81      0.80      6000\n",
      "           5       0.86      0.81      0.84      6000\n",
      "           6       0.45      0.45      0.45      6000\n",
      "           7       0.62      0.66      0.64      6000\n",
      "           8       0.68      0.70      0.69      6000\n",
      "           9       0.72      0.67      0.70      6000\n",
      "\n",
      "    accuracy                           0.64     60000\n",
      "   macro avg       0.65      0.64      0.64     60000\n",
      "weighted avg       0.65      0.64      0.64     60000\n",
      "\n",
      "\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:52<00:00, 18.13it/s, loss=0.1792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.1271\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:10<00:00, 26.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.48      0.50      6000\n",
      "           1       0.66      0.64      0.65      6000\n",
      "           2       0.69      0.73      0.71      6000\n",
      "           3       0.49      0.42      0.45      6000\n",
      "           4       0.73      0.85      0.78      6000\n",
      "           5       0.86      0.80      0.83      6000\n",
      "           6       0.45      0.41      0.43      6000\n",
      "           7       0.61      0.64      0.63      6000\n",
      "           8       0.66      0.71      0.68      6000\n",
      "           9       0.68      0.71      0.69      6000\n",
      "\n",
      "    accuracy                           0.64     60000\n",
      "   macro avg       0.63      0.64      0.64     60000\n",
      "weighted avg       0.63      0.64      0.64     60000\n",
      "\n",
      "\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:59<00:00, 17.43it/s, loss=0.1849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0914\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:09<00:00, 27.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.57      0.50      6000\n",
      "           1       0.71      0.57      0.63      6000\n",
      "           2       0.68      0.73      0.70      6000\n",
      "           3       0.47      0.41      0.44      6000\n",
      "           4       0.84      0.76      0.80      6000\n",
      "           5       0.88      0.78      0.83      6000\n",
      "           6       0.39      0.49      0.43      6000\n",
      "           7       0.65      0.60      0.62      6000\n",
      "           8       0.64      0.72      0.68      6000\n",
      "           9       0.73      0.64      0.68      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.64      0.63      0.63     60000\n",
      "weighted avg       0.64      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:01<00:00, 17.18it/s, loss=0.0340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0661\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:11<00:00, 26.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.53      0.51      6000\n",
      "           1       0.70      0.56      0.62      6000\n",
      "           2       0.74      0.69      0.71      6000\n",
      "           3       0.47      0.40      0.43      6000\n",
      "           4       0.80      0.79      0.79      6000\n",
      "           5       0.90      0.76      0.83      6000\n",
      "           6       0.41      0.48      0.44      6000\n",
      "           7       0.63      0.62      0.63      6000\n",
      "           8       0.64      0.72      0.68      6000\n",
      "           9       0.63      0.75      0.68      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.64      0.63      0.63     60000\n",
      "weighted avg       0.64      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:02<00:00, 17.16it/s, loss=0.0276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0505\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:11<00:00, 26.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.53      0.50      6000\n",
      "           1       0.70      0.57      0.63      6000\n",
      "           2       0.74      0.70      0.71      6000\n",
      "           3       0.46      0.43      0.45      6000\n",
      "           4       0.82      0.78      0.80      6000\n",
      "           5       0.91      0.72      0.81      6000\n",
      "           6       0.37      0.50      0.43      6000\n",
      "           7       0.64      0.61      0.62      6000\n",
      "           8       0.68      0.66      0.67      6000\n",
      "           9       0.63      0.74      0.68      6000\n",
      "\n",
      "    accuracy                           0.62     60000\n",
      "   macro avg       0.64      0.62      0.63     60000\n",
      "weighted avg       0.64      0.62      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:53<00:00, 17.98it/s, loss=0.0154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0373\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:09<00:00, 27.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.47      0.49      6000\n",
      "           1       0.71      0.54      0.62      6000\n",
      "           2       0.72      0.70      0.71      6000\n",
      "           3       0.43      0.46      0.44      6000\n",
      "           4       0.77      0.79      0.78      6000\n",
      "           5       0.85      0.81      0.82      6000\n",
      "           6       0.38      0.50      0.43      6000\n",
      "           7       0.63      0.61      0.62      6000\n",
      "           8       0.66      0.69      0.67      6000\n",
      "           9       0.70      0.68      0.69      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.64      0.63      0.63     60000\n",
      "weighted avg       0.64      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:03<00:00, 17.00it/s, loss=0.0068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0290\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:10<00:00, 26.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.49      0.50      6000\n",
      "           1       0.65      0.64      0.64      6000\n",
      "           2       0.68      0.72      0.70      6000\n",
      "           3       0.45      0.43      0.44      6000\n",
      "           4       0.78      0.80      0.79      6000\n",
      "           5       0.85      0.80      0.83      6000\n",
      "           6       0.43      0.45      0.44      6000\n",
      "           7       0.64      0.62      0.63      6000\n",
      "           8       0.69      0.65      0.67      6000\n",
      "           9       0.64      0.73      0.68      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:03<00:00, 17.07it/s, loss=0.0060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0214\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:09<00:00, 26.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.46      0.49      6000\n",
      "           1       0.68      0.61      0.64      6000\n",
      "           2       0.69      0.72      0.71      6000\n",
      "           3       0.43      0.46      0.44      6000\n",
      "           4       0.83      0.75      0.79      6000\n",
      "           5       0.89      0.77      0.83      6000\n",
      "           6       0.38      0.49      0.43      6000\n",
      "           7       0.66      0.60      0.63      6000\n",
      "           8       0.64      0.70      0.67      6000\n",
      "           9       0.66      0.72      0.69      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.64      0.63      0.63     60000\n",
      "weighted avg       0.64      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:03<00:00, 17.04it/s, loss=0.0019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0163\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:09<00:00, 27.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.48      0.50      6000\n",
      "           1       0.65      0.63      0.64      6000\n",
      "           2       0.72      0.70      0.71      6000\n",
      "           3       0.42      0.48      0.45      6000\n",
      "           4       0.71      0.84      0.77      6000\n",
      "           5       0.86      0.81      0.83      6000\n",
      "           6       0.46      0.39      0.43      6000\n",
      "           7       0.60      0.66      0.63      6000\n",
      "           8       0.69      0.65      0.67      6000\n",
      "           9       0.70      0.68      0.69      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:59<00:00, 17.41it/s, loss=0.0015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0114\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:11<00:00, 26.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.52      0.50      6000\n",
      "           1       0.67      0.62      0.64      6000\n",
      "           2       0.69      0.71      0.70      6000\n",
      "           3       0.50      0.36      0.42      6000\n",
      "           4       0.79      0.79      0.79      6000\n",
      "           5       0.83      0.81      0.82      6000\n",
      "           6       0.41      0.47      0.44      6000\n",
      "           7       0.58      0.66      0.62      6000\n",
      "           8       0.68      0.65      0.67      6000\n",
      "           9       0.69      0.67      0.68      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:03<00:00, 17.04it/s, loss=0.0003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0089\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:10<00:00, 26.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49      6000\n",
      "           1       0.69      0.60      0.64      6000\n",
      "           2       0.71      0.70      0.71      6000\n",
      "           3       0.47      0.43      0.45      6000\n",
      "           4       0.74      0.83      0.78      6000\n",
      "           5       0.89      0.77      0.82      6000\n",
      "           6       0.42      0.44      0.43      6000\n",
      "           7       0.61      0.62      0.62      6000\n",
      "           8       0.63      0.72      0.67      6000\n",
      "           9       0.67      0.71      0.69      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:07<00:00, 16.65it/s, loss=0.0024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0068\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:10<00:00, 26.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.49      0.49      6000\n",
      "           1       0.65      0.63      0.64      6000\n",
      "           2       0.70      0.70      0.70      6000\n",
      "           3       0.42      0.47      0.44      6000\n",
      "           4       0.81      0.77      0.79      6000\n",
      "           5       0.85      0.80      0.83      6000\n",
      "           6       0.41      0.46      0.43      6000\n",
      "           7       0.64      0.60      0.62      6000\n",
      "           8       0.68      0.66      0.67      6000\n",
      "           9       0.69      0.69      0.69      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.64      0.63      0.63     60000\n",
      "weighted avg       0.64      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:07<00:00, 16.68it/s, loss=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0051\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:10<00:00, 26.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49      6000\n",
      "           1       0.65      0.64      0.65      6000\n",
      "           2       0.64      0.74      0.69      6000\n",
      "           3       0.49      0.39      0.43      6000\n",
      "           4       0.77      0.80      0.79      6000\n",
      "           5       0.85      0.80      0.82      6000\n",
      "           6       0.45      0.40      0.42      6000\n",
      "           7       0.63      0.62      0.63      6000\n",
      "           8       0.62      0.72      0.67      6000\n",
      "           9       0.65      0.71      0.68      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:08<00:00, 16.61it/s, loss=0.0003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0038\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:09<00:00, 26.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.46      0.48      6000\n",
      "           1       0.69      0.61      0.65      6000\n",
      "           2       0.67      0.73      0.70      6000\n",
      "           3       0.50      0.38      0.43      6000\n",
      "           4       0.75      0.81      0.78      6000\n",
      "           5       0.84      0.81      0.83      6000\n",
      "           6       0.45      0.43      0.44      6000\n",
      "           7       0.59      0.66      0.62      6000\n",
      "           8       0.59      0.74      0.66      6000\n",
      "           9       0.68      0.69      0.69      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:53<00:00, 18.04it/s, loss=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0025\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:10<00:00, 26.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.49      0.49      6000\n",
      "           1       0.68      0.59      0.63      6000\n",
      "           2       0.71      0.70      0.71      6000\n",
      "           3       0.43      0.46      0.44      6000\n",
      "           4       0.78      0.79      0.78      6000\n",
      "           5       0.87      0.78      0.82      6000\n",
      "           6       0.39      0.49      0.43      6000\n",
      "           7       0.66      0.58      0.62      6000\n",
      "           8       0.68      0.67      0.68      6000\n",
      "           9       0.67      0.70      0.68      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.64      0.63      0.63     60000\n",
      "weighted avg       0.64      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:55<00:00, 17.80it/s, loss=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0017\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:09<00:00, 26.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.45      0.49      6000\n",
      "           1       0.67      0.60      0.63      6000\n",
      "           2       0.73      0.68      0.70      6000\n",
      "           3       0.45      0.42      0.44      6000\n",
      "           4       0.70      0.84      0.76      6000\n",
      "           5       0.84      0.80      0.82      6000\n",
      "           6       0.36      0.51      0.42      6000\n",
      "           7       0.60      0.63      0.61      6000\n",
      "           8       0.74      0.59      0.66      6000\n",
      "           9       0.69      0.66      0.68      6000\n",
      "\n",
      "    accuracy                           0.62     60000\n",
      "   macro avg       0.63      0.62      0.62     60000\n",
      "weighted avg       0.63      0.62      0.62     60000\n",
      "\n",
      "\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:56<00:00, 17.68it/s, loss=0.0003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0014\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:10<00:00, 26.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.45      0.49      6000\n",
      "           1       0.68      0.61      0.64      6000\n",
      "           2       0.72      0.68      0.70      6000\n",
      "           3       0.47      0.43      0.45      6000\n",
      "           4       0.75      0.82      0.78      6000\n",
      "           5       0.84      0.82      0.83      6000\n",
      "           6       0.40      0.48      0.44      6000\n",
      "           7       0.60      0.65      0.62      6000\n",
      "           8       0.67      0.68      0.67      6000\n",
      "           9       0.68      0.70      0.69      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [02:58<00:00, 17.53it/s, loss=0.0004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0010\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:23<00:00, 22.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.50      0.49      6000\n",
      "           1       0.68      0.60      0.64      6000\n",
      "           2       0.66      0.73      0.69      6000\n",
      "           3       0.46      0.42      0.44      6000\n",
      "           4       0.78      0.80      0.79      6000\n",
      "           5       0.85      0.80      0.83      6000\n",
      "           6       0.43      0.45      0.44      6000\n",
      "           7       0.63      0.62      0.62      6000\n",
      "           8       0.64      0.71      0.67      6000\n",
      "           9       0.70      0.66      0.68      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:30<00:00, 14.84it/s, loss=0.0003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0006\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:19<00:00, 23.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49      6000\n",
      "           1       0.68      0.61      0.64      6000\n",
      "           2       0.69      0.71      0.70      6000\n",
      "           3       0.44      0.45      0.45      6000\n",
      "           4       0.79      0.78      0.79      6000\n",
      "           5       0.85      0.81      0.83      6000\n",
      "           6       0.41      0.47      0.44      6000\n",
      "           7       0.66      0.59      0.62      6000\n",
      "           8       0.64      0.70      0.67      6000\n",
      "           9       0.68      0.70      0.69      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:58<00:00, 13.08it/s, loss=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0004\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:28<00:00, 21.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.49      0.49      6000\n",
      "           1       0.65      0.63      0.64      6000\n",
      "           2       0.71      0.68      0.70      6000\n",
      "           3       0.45      0.43      0.44      6000\n",
      "           4       0.75      0.81      0.78      6000\n",
      "           5       0.86      0.79      0.83      6000\n",
      "           6       0.40      0.48      0.44      6000\n",
      "           7       0.65      0.60      0.62      6000\n",
      "           8       0.68      0.67      0.67      6000\n",
      "           9       0.68      0.69      0.69      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [04:10<00:00, 12.45it/s, loss=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0002\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:29<00:00, 20.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.51      0.49      6000\n",
      "           1       0.67      0.61      0.64      6000\n",
      "           2       0.70      0.70      0.70      6000\n",
      "           3       0.45      0.43      0.44      6000\n",
      "           4       0.78      0.79      0.79      6000\n",
      "           5       0.83      0.81      0.82      6000\n",
      "           6       0.43      0.44      0.44      6000\n",
      "           7       0.65      0.61      0.63      6000\n",
      "           8       0.63      0.71      0.67      6000\n",
      "           9       0.69      0.68      0.69      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [04:01<00:00, 12.93it/s, loss=0.0001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0002\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:26<00:00, 21.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.50      0.49      6000\n",
      "           1       0.66      0.62      0.64      6000\n",
      "           2       0.69      0.70      0.70      6000\n",
      "           3       0.45      0.45      0.45      6000\n",
      "           4       0.78      0.79      0.79      6000\n",
      "           5       0.86      0.79      0.82      6000\n",
      "           6       0.42      0.43      0.43      6000\n",
      "           7       0.63      0.62      0.62      6000\n",
      "           8       0.67      0.69      0.68      6000\n",
      "           9       0.67      0.71      0.69      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n",
      "\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [03:50<00:00, 13.56it/s, loss=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0001\n",
      "\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1875/1875 [01:32<00:00, 20.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.51      0.49      6000\n",
      "           1       0.67      0.61      0.64      6000\n",
      "           2       0.68      0.71      0.70      6000\n",
      "           3       0.45      0.44      0.45      6000\n",
      "           4       0.77      0.80      0.79      6000\n",
      "           5       0.86      0.79      0.83      6000\n",
      "           6       0.41      0.46      0.43      6000\n",
      "           7       0.63      0.62      0.62      6000\n",
      "           8       0.68      0.67      0.67      6000\n",
      "           9       0.69      0.68      0.68      6000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.63      0.63      0.63     60000\n",
      "weighted avg       0.63      0.63      0.63     60000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training settings\n",
    "epochs = 30\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)  # Slightly higher learning rate\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "print('Starting training...')\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{epochs}')\n",
    "    \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(f'Average training loss: {train_loss:.4f}')\n",
    "    \n",
    "    print('\\nEvaluating...')\n",
    "    report = evaluate(model, test_loader, device)\n",
    "    print('\\nClassification Report:')\n",
    "    print(report)\n",
    "    \n",
    "    # Save model if it improves\n",
    "    accuracy = float(report.split('\\n')[-2].split()[-2])\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), 'best_yahoo_LMUformer_2layer.pt')\n",
    "        print(f'Saved best model with accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aditya-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
